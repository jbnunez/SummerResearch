{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Loading data...\n",
      "==>Data loaded succesfully.\n",
      "==>Data Relabeled succesfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Input, Flatten, Conv2D, MaxPooling2D\n",
    "import mnist_cnn_data as data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants to be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data from the imported file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data.X_train\n",
    "y_train = data.y_train\n",
    "\n",
    "X_test = data.X_test\n",
    "y_test = data.y_test\n",
    "\n",
    "m, height, width, channels= X_train.shape\n",
    "input_shape = (height, width, channels)\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model.  Archtecture is Convolutional layer, pooling layer, convolutional, pooling, flattening, dense, then dense output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Building Model.\n"
     ]
    }
   ],
   "source": [
    "print('==>Building Model.')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), \n",
    "                 data_format=\"channels_last\",\n",
    "                 activation='relu',input_shape=input_shape, ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model using mean square error as loss, stochastic gradient descent optimizer, and accuracy as the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Compiling Model.\n"
     ]
    }
   ],
   "source": [
    "print('==>Compiling Model.')\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Fitting Model.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 40s 839us/step - loss: 0.0092 - acc: 0.9368 - val_loss: 0.0033 - val_acc: 0.9792\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 41s 863us/step - loss: 0.0032 - acc: 0.9801 - val_loss: 0.0032 - val_acc: 0.9800\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 40s 835us/step - loss: 0.0024 - acc: 0.9844 - val_loss: 0.0028 - val_acc: 0.9829\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 202s 4ms/step - loss: 0.0022 - acc: 0.9863 - val_loss: 0.0032 - val_acc: 0.9806\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 40s 843us/step - loss: 0.0018 - acc: 0.9886 - val_loss: 0.0019 - val_acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a4033c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==>Fitting Model.')\n",
    "model.fit(x=X_train, y=y_train, batch_size=batch_size, \n",
    "    epochs=num_epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Evaluating Model.\n",
      "10000/10000 [==============================] - 3s 278us/step\n",
      "[0.001615688205636478, 0.99080000000000001]\n"
     ]
    }
   ],
   "source": [
    "print('==>Evaluating Model.')\n",
    "print(model.evaluate(x=X_test, y=y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
